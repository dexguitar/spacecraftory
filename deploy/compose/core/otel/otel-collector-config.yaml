# =============================================================================
# КОНФИГУРАЦИЯ OPENTELEMETRY COLLECTOR - ЦЕНТРАЛЬНЫЙ АГЕНТ СБОРА ТЕЛЕМЕТРИИ
# =============================================================================
#
# OpenTelemetry Collector - это универсальный агент для сбора, обработки и
# отправки телеметрических данных (метрики, трейсы, логи).
#
# Основные концепции:
# 1. RECEIVERS (приемники) - получают данные от приложений
# 2. PROCESSORS (обработчики) - трансформируют и обогащают данные
# 3. EXPORTERS (экспортеры) - отправляют данные в системы хранения
# 4. EXTENSIONS (расширения) - дополнительные возможности (health check, pprof)
# 5. PIPELINES (пайплайны) - связывают receivers, processors и exporters
#
# АРХИТЕКТУРА:
# - Logs:    App -> OTLP Receiver -> Batch -> Elasticsearch
# - Metrics: App -> OTLP Receiver -> Batch -> Prometheus Remote Write
# - Traces:  App -> OTLP Receiver -> Batch -> Jaeger (OTLP)

# =============================================================================
# RECEIVERS - ПРИЕМНИКИ ДАННЫХ ТЕЛЕМЕТРИИ
# =============================================================================
# Receivers определяют, КАК и ОТКУДА Collector получает телеметрические данные
# Это входные точки для метрик, трейсов и логов
receivers:
  # OTLP (OpenTelemetry Protocol) - стандартный протокол OpenTelemetry
  # Это современный, эффективный протокол для передачи всех типов телеметрии
  # Поддерживает как gRPC (бинарный), так и HTTP (JSON) форматы
  otlp:
    protocols:
      # gRPC протокол - рекомендуемый для production
      # Преимущества: высокая производительность, эффективное сжатие, streaming
      # Использует HTTP/2 и Protocol Buffers для оптимальной передачи данных
      grpc:
        # Адрес и порт для приема gRPC соединений
        # 0.0.0.0 означает "слушать на всех сетевых интерфейсах"
        endpoint: 0.0.0.0:4317
      http:
        # Адрес и порт для приема HTTP соединений
        endpoint: 0.0.0.0:4318

# =============================================================================
# PROCESSORS - ОБРАБОТЧИКИ ДАННЫХ
# =============================================================================
# Processors трансформируют, фильтруют и обогащают телеметрические данные
# Они выполняются в порядке, указанном в pipeline
processors:
  # BATCH PROCESSOR - группировка данных в пакеты
  # Критически важен для производительности! Без него каждый элемент отправляется отдельно
  # Группирует множество элементов в один запрос, что значительно снижает нагрузку
  batch:
    # Размер пакета - сколько элементов группировать вместе
    # Больше = эффективнее сеть, но больше задержка и память
    send_batch_size: 1000
    # Максимальное время ожидания неполного пакета
    # Гарантирует, что данные не будут ждать слишком долго
    timeout: 5s
    # Максимальное количество отправляемых элементов за один раз
    # Защищает от слишком больших пакетов
    send_batch_max_size: 1000

  # RESOURCE PROCESSOR - обогащение метаданными на уровне ресурса
  # Добавляет информацию о сервисе ко всем телеметрическим данным
  resource:
    attributes:
      # DEPLOYMENT ENVIRONMENT: окружение развертывания
      # Помогает различать данные из dev/staging/production
      - key: deployment.environment
        value: dev
        action: insert # добавляем только если атрибут не задан приложением

  # PROBABILISTIC SAMPLER - вероятностное семплирование для трейсов
  # Управляет объемом собираемых данных (особенно важно для production)
  probabilistic_sampler:
    # Процент трейсов, которые будут сохранены
    # 100% означает сохранение всех данных (хорошо для разработки)
    # В продакшене рекомендуется более низкий процент (1-10%) для снижения нагрузки
    sampling_percentage: 100

# =============================================================================
# EXPORTERS - ЭКСПОРТЕРЫ ДАННЫХ
# =============================================================================
# Exporters отправляют обработанные данные в системы хранения и анализа
# Это выходные точки телеметрических данных
exporters:
  # PROMETHEUS REMOTE WRITE - отправка метрик в Prometheus
  # Remote Write - это способ отправки метрик в Prometheus "проталкиванием" (push)
  # В отличие от обычного scraping, где Prometheus сам забирает данные
  prometheusremotewrite:
    # URL endpoint Prometheus для приема метрик
    # Prometheus автоматически предоставляет этот endpoint
    endpoint: http://prometheus:9090/api/v1/write

  # ELASTICSEARCH EXPORTER - отправка логов в Elasticsearch
  # Elasticsearch - распределенная поисковая система для хранения и индексации логов
  elasticsearch:
    # ENDPOINTS: список адресов Elasticsearch кластера
    # В production обычно несколько узлов для отказоустойчивости
    endpoints: ["http://elasticsearch:9200"]
    # TLS НАСТРОЙКИ: конфигурация безопасного соединения
    tls:
      # INSECURE: отключаем проверку сертификатов для локальной разработки
      # В production ОБЯЗАТЕЛЬНО включить проверку сертификатов
      insecure: true
    # LOGS INDEX: имя индекса для хранения логов в Elasticsearch
    # Можно использовать шаблоны: "logs-%{+yyyy.MM.dd}" для создания daily индексов
    logs_index: "otel-logs"
    # MAPPING: настройки индексации данных
    mapping:
      # ECS MODE: использовать Elastic Common Schema
      # Стандартизирует структуру полей логов для лучшей совместимости
      mode: ecs

  # OTLP EXPORTER ДЛЯ JAEGER - отправка трейсов в Jaeger
  # Jaeger - система для распределенной трассировки
  otlp/jaeger:
    # Эндпоинт Jaeger, принимающий OTLP формат
    # Jaeger v2 поддерживает OTLP протокол напрямую
    endpoint: jaeger:4317
    tls:
      # Отключение TLS для локальной разработки
      insecure: true

  # DEBUG EXPORTER - вывод данных в логи коллектора
  # Полезно для отладки и проверки работоспособности пайплайнов
  debug:
    # Уровень детализации логов
    verbosity: basic

# =============================================================================
# EXTENSIONS - ДОПОЛНИТЕЛЬНЫЕ КОМПОНЕНТЫ
# =============================================================================
# Extensions предоставляют дополнительную функциональность коллектора
extensions:
  # HEALTH CHECK: эндпоинт для проверки здоровья коллектора
  # Полезно для мониторинга в Kubernetes/Docker
  health_check:
    # ENDPOINT: адрес для health check запросов
    endpoint: 0.0.0.0:13133

# =============================================================================
# SERVICE - КОНФИГУРАЦИЯ СЕРВИСА
# =============================================================================
# Секция service связывает все компоненты вместе и настраивает сам Collector
service:
  # Включаем расширения
  extensions: [health_check]

  # Настройки телеметрии самого Collector
  # Collector тоже генерирует метрики о своей работе
  telemetry:
    # Метрики самого коллектора для мониторинга его состояния
    metrics:
      address: 0.0.0.0:8888 # Prometheus метрики коллектора

  # PIPELINES - ПАЙПЛАЙНЫ ОБРАБОТКИ ДАННЫХ
  # Пайплайн определяет путь данных: receiver -> processors -> exporters
  # Можно создать разные пайплайны для разных типов данных
  pipelines:
    # ==========================================================================
    # METRICS PIPELINE - обработка метрик
    # ==========================================================================
    # Обрабатывает метрики (счетчики, гистограммы, gauge)
    # Flow: App -> OTLP Receiver -> Batch -> Prometheus
    metrics:
      # Источники данных - получаем метрики от приложений через OTLP
      receivers: [otlp]
      # Последовательность обработки данных (порядок важен!)
      # resource - добавляем метаданные окружения
      # batch - группировка для эффективности отправки
      processors: [resource, batch]
      # Отправляем обработанные метрики в Prometheus
      exporters: [prometheusremotewrite]

    # ==========================================================================
    # LOGS PIPELINE - обработка логов
    # ==========================================================================
    # Обрабатывает логи от приложений
    # Flow: App -> OTLP Receiver -> Batch -> Elasticsearch
    logs:
      # Источники данных - получаем логи от приложений через OTLP
      receivers: [otlp]
      # Последовательность обработки данных
      # resource - добавляем метаданные окружения
      # batch - группировка для эффективности отправки
      processors: [resource, batch]
      # Отправляем обработанные логи в Elasticsearch
      exporters: [elasticsearch]

    # ==========================================================================
    # TRACES PIPELINE - обработка трейсов
    # ==========================================================================
    # Обрабатывает распределенные трейсы от приложений
    # Flow: App -> OTLP Receiver -> Sampler -> Batch -> Jaeger
    traces:
      # Источники данных - получаем трейсы от приложений через OTLP
      receivers: [otlp]
      # Последовательность обработки данных
      # probabilistic_sampler - семплирование трейсов (важно для production)
      # resource - добавляем метаданные окружения
      # batch - группировка для эффективности отправки
      processors: [probabilistic_sampler, resource, batch]
      # Отправляем обработанные трейсы в Jaeger
      exporters: [otlp/jaeger, debug]
˝